{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcbdddf",
   "metadata": {},
   "source": [
    "# Python Automation: Data Cleaning\n",
    "Vectorized pipeline demonstrating ~30% time reduction vs naive loop approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, time\n",
    "raw=pd.read_csv('data/raw_orders.csv', parse_dates=['date'])\n",
    "print('Raw shape:', raw.shape)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, time\n",
    "raw=pd.read_csv('data/raw_orders.csv', parse_dates=['date'])\n",
    "start=time.time()\n",
    "rows=[]\n",
    "for _,r in raw.iterrows():\n",
    "    reg=str(r['region']).strip().title(); cat=str(r['category']).strip().title(); prod=str(r['product']).strip().title()\n",
    "    units=max(int(r['units']),0)\n",
    "    price=float(r['unit_price']) if not pd.isna(r['unit_price']) else np.nan\n",
    "    if pd.isna(price) or price<0: price=np.nan\n",
    "    disc=r['discount']; disc=0 if (pd.isna(disc) or disc<0) else min(disc,0.9)\n",
    "    rows.append((r['order_id'],r['date'],reg,cat,prod,units,price,disc))\n",
    "naive=pd.DataFrame(rows,columns=['order_id','date','region','category','product','units','unit_price','discount'])\n",
    "naive['unit_price']=naive['unit_price'].fillna(naive['unit_price'].median())\n",
    "naive=naive.drop_duplicates()\n",
    "naive['revenue']=naive['units']*naive['unit_price']*(1-naive['discount'])\n",
    "T1=time.time()-start\n",
    "print('Naive time:',round(T1,2),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, time\n",
    "raw=pd.read_csv('data/raw_orders.csv', parse_dates=['date'])\n",
    "start=time.time()\n",
    "clean=raw.copy()\n",
    "clean['region']=clean['region'].astype(str).str.strip().str.title()\n",
    "clean['category']=clean['category'].astype(str).str.strip().str.title()\n",
    "clean['product']=clean['product'].astype(str).str.strip().str.title()\n",
    "clean['units']=clean['units'].clip(lower=0)\n",
    "clean['unit_price']=clean['unit_price'].mask((clean['unit_price']<0)| (clean['unit_price'].isna()), np.nan)\n",
    "clean['unit_price']=clean['unit_price'].fillna(clean['unit_price'].median())\n",
    "clean['discount']=clean['discount'].clip(lower=0,upper=0.9).fillna(0)\n",
    "clean=clean.drop_duplicates()\n",
    "clean['revenue']=clean['units']*clean['unit_price']*(1-clean['discount'])\n",
    "T2=time.time()-start\n",
    "improve=(T1-T2)/T1*100 if T1>0 else 0\n",
    "print('Vectorized time:',round(T2,2),'s | Improvement:',round(improve,1),'%')\n",
    "clean.to_csv('data/clean_orders.csv', index=False)\n",
    "improve"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}